Citations:
Balazs explained to me what the point of the first part of benchmarking was. I understood that it was to determine the efficiency of different x86 Assembly instructions. He also told me that div was special in that rdx was used. I discussed possible matrix algorithms with Alex Dai and Alex You, and how we could use blocks of 32 to optimize the cache storage to reduce the number of cycles per comparison. Together, we found out that there were special cases in which the matrix lenght might not be divisible by our block size (32), so I added different for loops that would take care of this. Me and Joseph talked about how we could measure the efficiency of dependent loads. I got the original idea of using block sizes to use the cache efficiently from stack overflow where someone was trying to find an algorithm to transpose a matrix.

(1) Explain what you did in order to tune for performance of your balance()
    function

What I did to improve the peformance of the balance() function was to read in values in chunks of 32. This way we would optimize the use of the cache since the block size is 32. We would only have to fetch from memory once every 32 times as long as the matrix length was divisible by 32. This compromised of 4 for loops and making square blocks of length 32 x 32 to reduce the number of cycles per comparison. There are 3 edge cases: the diagonal, the right margin, and the bottom margin. We have a special case for the diagonal because we are going in square blocks, and a square block right next to the diagonal will overlap into the bottom triangular matrix and double count some values. To avoid this, we only traverse the upper triangular by going in triangles when we are 32 elements away from the diagonal. The right margin is a special case because the number of columns in the matrix might not be divisible by 32. We have to account for the remainder of the columns by using the naive algorithm to calculate the balance. The same goes for the bottom margin except it is for rows. The basic blocks, and the 3 special cases constitute the whole upper triangular matrix, which is what my original naive solution covers. The only difference is the way in which the elements are accessed and compared.


(2) Which instructions are pipelined and which instructions are not? explain

All the instructions are pipelined. Even the dependent ones are pipelined. The reason the dependent instructions are slower than the independent ones is that it relies on forwarding to retrieve some of its values and it may stop the pipeline depending on the immplementation. However, similar to our projects p9 and p10, all instructions are pipelined.


(3) How many fixed-point unit does your processor have?

Fixed-point units are ALUs. Our Intel Haswell i7 processor has 8 ALUs.


(4) How many of them know how to add?

The number of fixed-point units that know how to add is the time it takes for the independent add divided by the dependent add. This is 3.374/1.111 ~= 3.


(5) How many of them know how to divide?

The number of fixed-point units that know how to divide is the time it takes for the independent add divided by the dependent add. This is 0.049/0.034 = 1.5 which rounds up to 2.


(6) How many of them know how to multiply?

The number of fixed-point units that know how to multiply is the time it takes for the independent multiply divided by the dependent multiply. This is 1.108/0.371 ~= 3.


(7) How many load units does your processor have?

4 load units.
